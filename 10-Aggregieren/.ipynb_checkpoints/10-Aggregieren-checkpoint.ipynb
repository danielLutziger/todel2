{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 10: Aggregation von Daten und Gruppenoperationen\n",
    "\n",
    "McKinney, W. (2017). *Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython*. 2. Auflage. Sebastopol, CA [u. a.]: O’Reilly.\n",
    "\n",
    "Überarbeitet: armin.baenziger@zhaw.ch, 25. Nov. 2020\n",
    "\n",
    "- Das Kategorisieren eines Datasets und das Anwenden einer Funktion auf jede Gruppe, ob Aggregation oder Transformation, ist häufig eine kritische Komponente eines Datenanalyseworkflows.\n",
    "- Pandas bietet dazu eine flexible `groupby`-Methode an.\n",
    "- Hilfreich sind zudem Funktionen für Pivot-Tabellen und Kreuztabellen, welche einen Spezialfall von Pivott-Tabellen darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wichtige Bibliotheken mit üblichen Abkürzungen laden:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damit Plots direkt im Notebook erscheinen:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## GroupBy-Mechanismen\n",
    "- Gruppenoperationen lassen sich mit dem Begriff **\"Split-Apply-Combine\"** beschreiben.\n",
    "- In der ersten Phase des Prozesses werden Daten, die in einem Pandas-Objekt enthalten sind basierend auf einem oder mehreren Schlüsseln in Gruppen aufgeteilt. \n",
    "- Das Teilen wird auf einer bestimmten Achse eines Objekts ausgeführt. Zum Beispiel kann ein DataFrame in seinen Zeilen (Achse = 0) oder seinen Spalten (Achse = 1) gruppiert werden. \n",
    "- Sobald dies erledigt ist, wird eine Funktion auf jede Gruppe angewendet, wodurch ein neuer Wert erzeugt wird. \n",
    "- Abschliessend werden die Ergebnisse all dieser Funktionsanwendungen zu einem Ergebnisobjekt zusammengefasst.\n",
    "- Die folgende Abbildung aus dem Lehrmittel stellt den GroupBy-Mechanismus dar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Figure_10_1_Illustration_GroupBy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstes Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key'  : list('ABCABCABC'),\n",
    "                   'data' : [0, 2, 5, 3, 1, 7, 2, 0, 4]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.data.groupby(df.key)\n",
    "grouped   # Dieses Objekt ist ein sog. GroupBy-Objekt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das GroupBy-Objekt kann nun verwendet werden, um beispielsweise Gruppenstatistiken zu erstellen. Im Folgenden summieren wir die Werte in `data` für jede Gruppe in `key` separat auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiteres Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
    "                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
    "                   'data1' : np.random.randint(low=1, high=7, size=5),\n",
    "                   'data2' : np.random.randint(low=1, high=7, size=5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.data1.groupby(df.key1).mean() \n",
    "# data1 nach key1 gruppieren und Mittelwerte berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df.data1.groupby([df.key1, df.key2]).mean()\n",
    "# Gruppierung nach key1 und danach key2.\n",
    "means # Es entsteht eine Series mit hierarchischem Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Erinnerung: Mit `unstack` können wir eine (zweite per Default) Hierarchieebene in die Spalten drehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means.unstack() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means.unstack().plot.bar(\n",
    "    title='Gruppenmittelwerte', rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiteres Beispiel: In obigen Beispielen sind die Gruppenschlüssel Series bzw. Spalten von DataFrames. Die Gruppenschlüssel können aber *irgendwelche Arrays sein, solange sie die richtige Länge haben!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df # Beispieldatei nochmals betrachten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gruppen = np.array(['G1', 'G2', 'G2', 'G1', 'G1'])\n",
    "df.groupby(Gruppen).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinweis: Die Mittelwerte für `key1` und `key2` fehlen oben, da die Merkmale nicht numerisch sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Häufig befinden sich die Gruppierungsinformationen im selben DataFrame wie die Daten, die analysiert werden sollen. In diesem Fall können Spaltennamen (ob Zeichenfolgen, Zahlen oder andere Python-Objekte) als Gruppenschlüssel übergeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ungeachtet der Zielsetzung bei der Verwendung von `groupby` ist `size` eine allgemein nützliche GroupBy-Methode, die eine *Series* mit den Gruppengrössen zurückgibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Gegensatz zu `size` werden bei `count` die Anzahl Werte (ohne Fehlwerte!) *pro Spalte* ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da keine `NaN` existieren, haben wir in beiden Spalten die gleichen Werte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zwei Wege zu gruppieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1').data1.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.data1.groupby(df.key1).median() \n",
    "# Achtung, df.key1 hier, nicht 'key1', da\n",
    "# key1 nicht mehr in df.data1 enthalten ist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beide Zeilen führen zum gleichen Resultat. \n",
    "- Die erste Zeile ist prägnanter. \n",
    "- *Die zweite Zeile ist insb. in grossen Datensätzen vorzuziehen, da weiger Daten aggregiert werden müssen.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kontrollfragen:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben:\n",
    "dflohn = pd.read_pickle('../weitere_Daten/dflohn.pkl')\n",
    "dflohn_sample = (dflohn.sample(5, random_state=13)\n",
    "                .sort_values(['Geschlecht', 'Zivilstand']))\n",
    "dflohn_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage 1: Was ist der Output?\n",
    "dflohn_sample.groupby('Geschlecht').Lohn.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage 2: Was ist der Output?\n",
    "dflohn_sample.groupby(\n",
    "    ['Geschlecht', 'Zivilstand']).Alter.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage 3: Was ist der Output?\n",
    "Abteilung = [1, 2, 2, 1, 1]\n",
    "dflohn_sample.Lohn.groupby(Abteilung).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation von Daten\n",
    "- **Aggregationen nennt man Datenumwandlungen, die skalare Werte aus Arrays erzeugen.** \n",
    "- Die vorhergehenden Beispiele haben mehrere von ihnen verwendet.\n",
    "- Viele häufig verwendete Aggregationen haben optimierte `groupby`-Implementierungen. Es sind dies: `count`, `sum`, `mean`, `median`, `std/var`, `min/max`, `prod`, `first/last` (erster und letzter Nicht-`NaN`-Wert).\n",
    "- Zudem kann jede Methode aufgerufen werden, die auch für das gruppierte Objekt definiert ist. Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übersichtliche Darstellung des Beispiel-DataFrames:\n",
    "df2 = df.drop('key2', axis=1).sort_values(['key1', 'data1'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gruppiert = df2.groupby('key1')\n",
    "gruppiert.quantile(0.25) # 25%-Quantil = 1. Quartil   \n",
    "# Hinweis: Bei so wenigen Werten ist die Bestimmung\n",
    "# des 1. Quartils nicht wirklich sinnvoll. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es fuktionieren auch Methoden wie `describe`, obwohl sie streng genommen keine Aggregationen sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gruppiert['data1'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Schliesslich ist es auch möglich, *eigene* Aggregationen zu verwenden.\n",
    "- Um eigene Aggregationsfunktionen zu verwenden, übergibt man eine Funktion, die ein Array aggregiert, an die **`aggregate`**- oder **`agg`**-Methode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spannweite(x):\n",
    "    return x.max() - x.min()\n",
    "gruppiert.agg(spannweite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exkurs: oder direkt mit einer Lambda-Funktion \n",
    "# (keine explizite Funktionsdefinition nötig):\n",
    "gruppiert.agg(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weitere Funktionalitäten dargestellt am \"Trinkgelddatensatz\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv('../examples/tips.csv')\n",
    "# Variable hinzufügen, welche Trinkgeld als\n",
    "# Prozent des Rechnungstotals ausdrückt:\n",
    "tips['tip_pct'] = tips.tip / tips.total_bill\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = tips.groupby(['day', 'smoker'])\n",
    "grouped.mean()   # Mittelwerte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnungen nur für eine Variable:\n",
    "grouped['tip_pct'].mean()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped['tip_pct'].agg('mean')  # gleiches Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit agg können wir auch mehrere Aggregationen \n",
    "# gleichzeitig durchführen:\n",
    "grouped['tip_pct'].agg(['mean', 'std', spannweite])\n",
    "# 'mean' und 'std' sind Abkürzungen für np.mean\n",
    "# und np.std. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kontrollfrage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben:\n",
    "dflohn_sample.sort_values('Zivilstand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage: Was ist der Output?\n",
    "dflohn_sample.groupby('Zivilstand'\n",
    "              ).Alter.agg(['size', 'sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Apply-Methode\n",
    "Die allgemeinste GroupBy-Methode ist `apply`, welche Gegenstand der folgenden Ausführungen ist. Mit `apply` können Funktionen entlang einer Achse ausgeführt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflohn.groupby('Geschlecht').Lohn.apply(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zuvor gezeigt, könnte man diese Aggregation auch mit `agg` oder direkt mit `mean` umsetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflohn.groupby('Geschlecht').Lohn.agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oder:\n",
    "dflohn.groupby('Geschlecht').Lohn.agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oder direkt:\n",
    "dflohn.groupby('Geschlecht').Lohn.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `apply` können aber neben Aggregationen weitere Funktionen auf Gruppen angewendet werden. Kehren wir hierzu zum vorherigen Trinkgeld-Datensatz zurück. Angenommen wir wollen eine Funktion schreiben, welche die `n` (Default `n=3`) grössten Werte der Spalte `by` (Default `by=tip_pct`) zurückgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(df, n=3, by='tip_pct'): \n",
    "    # \"Positional-Argument\" (df) vor \"Keyword-Argumenten (n, by)\"\n",
    "    return df.sort_values(by=by, ascending=False)[:n]\n",
    "\n",
    "top(tips, by='tip', n=1)  # höchstes (absolutes) Trinkgeld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohne weitere Argumente gelten die Defaults, also `n=3` und `by=tip_pct`, also die drei höchsten *prozentualen* Trinkgelder relativ zum Rechnungsbetrag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top(tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir nun beispielsweise nach der Spalte `smoker` gruppieren und `apply` mit dieser Funktion aufrufen, erhalten wir Folgendes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby('smoker').apply(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten somit die höchsten drei prozentualen Trinkgleder *pro Gruppe*. Auch hier könnte man die Defaults überschreiben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pro Gruppe die zwei höchsten absoluten Trinkgelder:\n",
    "tips.groupby('smoker').apply(top, by='tip', n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten nun die zwei höchsten (absoluten) Trinkgelder pro Gruppe (Nichtraucher, Raucher)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kontrollfrage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben:\n",
    "dflohn_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage: Was ist der Output?\n",
    "dflohn_sample.groupby('Geschlecht').apply(\n",
    "            top, by='Lohn', n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: Standardabweichung der Tagesrenditen separat pro Jahr\n",
    "Als Beispiel betrachten wir einen Finanzdatensatz, der von Yahoo-Finance stammt, mit Tagesendkursen einiger Aktien und dem S&P500-Index (Symbol SPX):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_px = pd.read_csv('../examples/stock_px_2.csv', \n",
    "                       parse_dates=True, index_col=0)\n",
    "close_px.head()  # die ersten 5 Zeilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_px.tail()   # die letzten 5 Zeilen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die praktische Methode `pct_change` berechnet die prozentaulen Veränderungen aus den Kursdaten (also die Renditen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = close_px.pct_change().dropna()\n",
    "# Wir verwenden dropna, da am Anfang des DataFrames\n",
    "# durch die Renditeberechnungen NaN entstanden.\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardabweichungen der Tagesrenditen über den ganzen Zeitraum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes berechnen wir die Korrelationen der Aktien mit dem Aktienindex (SPX) *pro Jahr*. Zuerst halten wir fest, dass man die Jahre wie folgt aus dem Datum ziehen kann (Details folgen im Kapitel 11):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.index.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können somit `returns.index.year` als Gruppierungsvektor übergeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Std_pro_Jahr = returns.groupby(returns.index.year).std()\n",
    "Std_pro_Jahr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Standardabweichungen steigen mit der Finanzkrise an und sinken dann wieder. Wir können dies auch graphisch verdeutlichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Std_pro_Jahr.plot(\n",
    "     title='Entwicklung der Standardabweichungen der Tagesrenditen');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kontrollfrage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben:\n",
    "Auto = pd.read_csv('../weitere_Daten/Auto.csv', sep=';')\n",
    "Auto.origin.replace({1: 'USA', 2: 'Europa', 3:'Japan'}, inplace=True)\n",
    "Auto.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben:\n",
    "def MittlereAnzahlBuchstaben(Zeichenkette):\n",
    "    return Zeichenkette.str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage: Was bedeutet der Output?\n",
    "Auto.groupby('origin')['name'].apply(MittlereAnzahlBuchstaben)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot-Tabellen und Kreuztabellierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angenommen wir wollen Gruppenmittelwerte arrangiert nach `day` und `smoker`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby(['day', 'smoker']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Tabelle ist der Default der Methode `pivot_table`. Somit hätten wir die Tabelle auch wie folgt erhalten (die Spalten folgen aber einer anderen Reihenfolge):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(index=['day', 'smoker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Methode erlaubt mehr: Es sollen die Grössen der Restaurantbesuchergruppen nach Tageszeit, Wochentag und ob sie rauchen oder nicht untersucht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(\n",
    "    values  = 'size',   # values: Welche Variable soll ausgewertet werden (Default Mittelwert)\n",
    "    index   = ['time', 'day'], # index: Gruppierung/Aufgliederung im Index\n",
    "    columns = 'smoker',        # columns: Aufgliederung in den Spalten\n",
    "    aggfunc = 'mean')          # Die Aggregationsfunktion 'mean' ist der Default\n",
    "                               # und könnte somit weggelassen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inklusive \"Randstatistiken\" mit dem Argument `margins=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(values  = ['size'], \n",
    "                 index   = ['time', 'day'],\n",
    "                 columns = 'smoker', \n",
    "                 margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine andere Aggregationsfunktion zu verwenden (als `mean`), übergibt man diese an `aggfunc`. Beispielsweise erhalten wir mit `len` oder `'count'` (`'count'`, nicht `count`) die absoluten Häufigkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = tips.pivot_table(values  = ['total_bill'], \n",
    "                       index   = ['time', 'smoker'], \n",
    "                       columns = 'day', \n",
    "                       aggfunc='count', \n",
    "                       margins=True)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn einige Zellen leer bzw. `NaN` sind, kann es sinnvoll sein, einen `fill_value` zu übergeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = tips.pivot_table(values='size', \n",
    "                       index=['time', 'smoker'], \n",
    "                       columns='day', \n",
    "                       aggfunc='count', fill_value=0,\n",
    "                       margins=True)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kontrollfrage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gegeben:\n",
    "Auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage: Wie ist der Output zu interpretieren?\n",
    "subset = Auto.cylinders.isin([4, 6, 8])  # nur Autos mit 4, 6 oder 8 Zylindern\n",
    "Auto[subset].pivot_table(values  = 'mpg',\n",
    "                         index   = 'origin',\n",
    "                         columns = 'cylinders',\n",
    "                         margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kreuztabellen\n",
    "Eine **Kreuztabelle** (auch **Kontingenztabelle** oder **Kontingenztafel** genannt) ist ein *Spezialfall einer Pivot-Tabelle*, die Gruppen**häufigkeiten** darstellt. Beispiele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=Auto.cylinders, \n",
    "            columns=Auto.origin,\n",
    "            margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesebeispiel: Es gibt im Datensatz 199 Autos mit 4 Zylindern, wobei 61 davon aus Europa stammen.  \n",
    "\n",
    "Das nächste Beispiel wiederholt eine Tabelle, die wir zuvor mit `pivot_table` erstellt haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index   = [tips.time, tips.smoker], \n",
    "            columns = tips.day, \n",
    "            margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiteres Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflohn = pd.read_pickle('../weitere_Daten/dflohn.pkl')\n",
    "dflohn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index = dflohn.Geschlecht, \n",
    "            columns = dflohn.Zivilstand, \n",
    "            margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 Personen im Datensatz sind männlich (m) und geschieden (g) usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Häufigkeitstabelle:\n",
    "pd.crosstab(index     = dflohn.Geschlecht, \n",
    "            columns   = dflohn.Zivilstand, \n",
    "            normalize = True, \n",
    "            margins   = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11% der Presonen im Datensatz sind männlich (m) und geschieden (g) usw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bedingte Häufigkeitstabellen:**\n",
    "\n",
    "Oft ist es hilfreich, wenn man bedingte relative Häufigkeiten ausweist um Strukturunterschiede in den Daten festzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1 = pd.crosstab(\n",
    "          index     = dflohn.Geschlecht, \n",
    "          columns   = dflohn.Zivilstand, \n",
    "          normalize = 'columns',     # Spalten auf 1 normieren.\n",
    "          margins   = True)\n",
    "tab1.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die relativen Häufigkeiten sind pro Spalte (Zivilstand) \"normalisiert\". Somit sind die Spaltentotale jeweils 1 (100%). Beispielsweise sind (im Datensatz) unter den Geschiedenen (g) 44% Männer und 56% Frauen. Insgesamt (All) sind im Datensatz 50% Männer und 50% Frauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kontrollfrage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage: Wie ist der erste Wert in der Tabelle (unter \"m\" und \"g\") zu interpretieren?\n",
    "tab2 = pd.crosstab(index     = dflohn.Geschlecht, \n",
    "                   columns   = dflohn.Zivilstand, \n",
    "                   normalize = 'index', \n",
    "                   margins   = True)\n",
    "tab2.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "- Die Beherrschung der Datengruppierungstools von Pandas ist sowohl bei der Datenbereinigung als auch bei der statistischen Analyse oder Modellierung sehr hilfreich.\n",
    "- Im nächsten Kapitel befassen wir uns mit Zeitreihendaten."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
